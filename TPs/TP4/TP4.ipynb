{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34203b95",
   "metadata": {},
   "source": [
    "# TRABAJO PRÁCTICO 4 - KNN Y ANÁLISIS DEL DISCRIMINANTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2de53ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import pairplot \n",
    "from sklearn import model_selection as ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686974a",
   "metadata": {},
   "source": [
    "## Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c18f2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 11)\n",
      "(211,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Se cargan los datos del csv\n",
    "df = pd.read_csv('MulticlassDiabetesDataset.csv')\n",
    "\n",
    "p_test = 0.2\n",
    "p_train = 0.8\n",
    "\n",
    "#Cantidad de muestras por clase\n",
    "# print(df.shape[0])\n",
    "\n",
    "#Gráfico con pairplot\n",
    "# pairplot(df)\n",
    "\n",
    "#Se definen los conjuntos de entrenamiento y testeo \n",
    "[train,test] = ms.train_test_split(df, train_size = p_train ,test_size = p_test)\n",
    "\n",
    "y_train=train['Class'].sort_index()\n",
    "x_train = train.drop(columns = ['Class']).sort_index()\n",
    "\n",
    "y_test = test['Class'].sort_index()\n",
    "x_test = test.drop(columns = ['Class']).sort_index()\n",
    "\n",
    "n_cat = len(np.unique(y_train))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(n_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3709c",
   "metadata": {},
   "source": [
    "## Análisis del discriminante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59197a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_QDA:\n",
    "    def __init__ (self, LDA = False, n_cat = 0):\n",
    "        self.LDA = LDA #Se define si se quiere el modelo LDA o QDA\n",
    "        self.n_cat = n_cat #Se guarda la cantidad de categorías en el problema\n",
    "        self.D = None #Clasificaciones\n",
    "        self.c = None #Probabilidades\n",
    "        self.sigma = None #Matriz de covarianza\n",
    "        self.sigma_lda = None #Matriz de covarianza para LDA\n",
    "\n",
    "    #Testeo de entrenamiento\n",
    "    def fit (self, X, y):\n",
    "        \n",
    "        #Se separan las muestras que corresponden a cada categoría en D (D_k)\n",
    "        self.D = [X[y==i] for i in range(self.n_cat)]\n",
    "\n",
    "        n_samples = X.shape[0] #Se guarda la cantidad de muestras\n",
    "        self.c = []\n",
    "        self.mu = []\n",
    "        self.sigma = []\n",
    "        \n",
    "        if self.LDA == True:\n",
    "            self.sigma_lda = []\n",
    "\n",
    "        for i in range(self.n_cat):\n",
    "            #Se calculan las constantes para cada conjunto\n",
    "            self.c.append( self.D[i].shape[0]/n_samples )\n",
    "\n",
    "            #Se calcula la media de cada categoría en cada feature\n",
    "            self.mu.append( (1/self.D[i].shape[0]) * np.sum(self.D[i],axis = 0) )\n",
    "\n",
    "            #Se calcula sigma para cada categoría\n",
    "            self.sigma.append( (1/(self.D[i].shape[0]-1)) * (self.D[i]-self.mu[i]).T @ (self.D[i]-self.mu[i]) )\n",
    "\n",
    "            #Se calcula el sigma que se utiliza en el método LDA para cada categoría\n",
    "            if self.LDA == True:\n",
    "                self.sigma_lda.append( (1/(n_samples-self.n_cat)) * (self.D[i].shape[0] -1 ) * self.sigma[i] )\n",
    "        \n",
    "        if self.LDA == True:\n",
    "            self.sigma_lda = np.sum(self.sigma_lda,axis = 0) #Se calcula el sigma resultante para utilizar en LDA tras el calculo por categorías\n",
    "            \n",
    "        # print(len(self.sigma))\n",
    "        # print(self.sigma_lda[0].shape)\n",
    "        # print(self.D[0].shape)\n",
    "        # print(len(self.mu))\n",
    "        # print(self.D[0].shape)\n",
    "        # print(self.D[1].shape)\n",
    "        # print(self.D[2].shape)\n",
    "        \n",
    "        \n",
    "    # #Testeo soft\n",
    "    def predict_prob (self, X):\n",
    "        delta = self.predict_discriminant(X)\n",
    "        exp_delta = np.exp(delta)\n",
    "        pred_soft = exp_delta / np.sum(exp_delta, axis=1, keepdims=True) #Se calcula la predicción soft, cuidando de hacer la suma en cada fila de forma correcta\n",
    "        return pred_soft\n",
    "        \n",
    "\n",
    "    # #Testeo hard\n",
    "    def predict (self, X):\n",
    "        delta = self.predict_discriminant(X)\n",
    "        pred_hard = np.argmax(delta,axis=1)\n",
    "        return pred_hard\n",
    "\n",
    "\n",
    "    #Alternativa práctica para el testeo soft\n",
    "    def predict_discriminant(self, X):\n",
    "        \n",
    "        if hasattr(X, \"values\"):\n",
    "            x = X.values\n",
    "        else:\n",
    "            x = np.array(X)\n",
    "\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(-1, 1)\n",
    "            \n",
    "            \n",
    "        delta = np.zeros((x.shape[0], self.n_cat)) #Se crea un array de los deltas de n_muestras x n_categorias\n",
    "        if self.LDA == True:\n",
    "            \n",
    "            if np.ndim(self.sigma_lda)> 0:        #Para múltiples dimensiones\n",
    "                inv_sigma_lda = np.linalg.inv(self.sigma_lda) #Se calcula la inversa de la matriz sigma para evitar repetir cálculos\n",
    "                for j in range(x.shape[0]): #Se calcula el discriminante en cada x, en las n_cat\n",
    "                    for i in range(self.n_cat):\n",
    "                        delta[j,i] = np.log(self.c[i]) + x[j,:].T @ inv_sigma_lda @ self.mu[i] - 0.5 * self.mu[i].T @ inv_sigma_lda @ self.mu[i]\n",
    "            \n",
    "            else:  #Para 1 dimensión\n",
    "                inv_sigma_lda = 1.0/self.sigma_lda #Se calcula la inversa de la matriz sigma para evitar repetir cálculos\n",
    "                for j in range(x.shape[0]): #Se calcula el discriminante en cada x, en las n_cat\n",
    "                    for i in range(self.n_cat):\n",
    "                        delta[j,i] = np.log(self.c[i]) + x[j,:].T @ inv_sigma_lda @ self.mu[i] - 0.5 * self.mu[i].T @ inv_sigma_lda @ self.mu[i]\n",
    "\n",
    "        else: \n",
    "            if np.ndim(self.sigma_lda) > 0:\n",
    "                for j in range(x.shape[0]): #Se calcula el discriminante para cada muestra en las n features, usando QDA\n",
    "                    for i in range(self.n_cat):\n",
    "                        diff = x[j,:]-self.mu[i] #Se calcula la diferencia para cada muestra en las n categorías para evitar repetir cálculos\n",
    "                        delta[j,i] = np.log(self.c[i]) - (0.5) * diff.T @ np.linalg.inv(self.sigma[i]) @ (diff) - 0.5 * np.log(np.linalg.det(self.sigma[i]))\n",
    "                \n",
    "        return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d319d26a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Evaluar discriminante en cada punto de la grilla\u001b[39;00m\n\u001b[0;32m     24\u001b[0m grid_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[xx\u001b[38;5;241m.\u001b[39mravel(), yy\u001b[38;5;241m.\u001b[39mravel()]\n\u001b[1;32m---> 25\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_lda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_discriminant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Clasificación dura en la grilla\u001b[39;00m\n\u001b[0;32m     28\u001b[0m Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(delta, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[207], line 91\u001b[0m, in \u001b[0;36mLDA_QDA.predict_discriminant\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]): \u001b[38;5;66;03m#Se calcula el discriminante en cada x, en las n_cat\u001b[39;00m\n\u001b[0;32m     90\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_cat):\n\u001b[1;32m---> 91\u001b[0m                 delta[j,i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc[i]) \u001b[38;5;241m+\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minv_sigma_lda\u001b[49m \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu[i] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu[i]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m inv_sigma_lda \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu[i]\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_lda) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "#Se selecciona el feature 'HbA1c' para entrenar el modelo\n",
    "selected_feature_train = np.array(x_train['HbA1c'])\n",
    "\n",
    "#Entrenamiento LDA\n",
    "model_lda = LDA_QDA(LDA = True, n_cat = 3)\n",
    "\n",
    "model_lda.fit(selected_feature_train,y_train)\n",
    "\n",
    "#Entrenamiento QDA\n",
    "model_qda = LDA_QDA(n_cat = 3)\n",
    "\n",
    "model_qda.fit(selected_feature_train,y_train)\n",
    "\n",
    "#Se grafica la Función Discriminante\n",
    "\n",
    "x_min, x_max = selected_feature_train.min() - 1, selected_feature_train.max() + 1\n",
    "y_min, y_max = selected_feature_train.min() - 1, selected_feature_train.max() + 1\n",
    "    \n",
    "    # Crear malla\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Evaluar discriminante en cada punto de la grilla\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "delta = model_lda.predict_discriminant(grid_points)\n",
    "    \n",
    "# Clasificación dura en la grilla\n",
    "Z = np.argmax(delta, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Dibujar frontera con contourf\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.tab10)\n",
    "\n",
    "# También graficar líneas de nivel de discriminantes\n",
    "for i in range(model_lda.n_cat):\n",
    "    plt.contour(xx, yy, delta[:, i].reshape(xx.shape), \n",
    "                levels=5, alpha=0.5, cmap=\"coolwarm\")\n",
    "\n",
    "# Puntos originales\n",
    "scatter = plt.scatter(selected_feature_train[:, 0], selected_feature_train[:, 1], c=y_train, cmap=plt.cm.tab10, edgecolor=\"k\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Clases\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Fronteras de decisión y funciones discriminantes\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
