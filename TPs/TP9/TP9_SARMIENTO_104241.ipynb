{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ee27f8",
   "metadata": {},
   "source": [
    "# TRABAJO PRÁCTICO 9 - NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "1146d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "\n",
    "#Generales\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "#Descarga del catálogo\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "#Manejo de los epubs\n",
    "import os\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ec4b2",
   "metadata": {},
   "source": [
    "# Procesamiento del catálogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e57c7e",
   "metadata": {},
   "source": [
    "#### Descarga del catálogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "0e881616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando compressed.tar...\n",
      "Descarga de archivos completa.\n",
      "La carpeta 'compressed' ya existe, no se vuelve a extraer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se colocan las URLs de los archivos a descargar\n",
    "url_catalog = \"https://web.csc.gob.ar/~jzuloaga/epub/catalog.csv\"\n",
    "url_tar = \"https://web.csc.gob.ar/~jzuloaga/epub/compressed.tar\"\n",
    "\n",
    "# Se colocan nombres a los archivos\n",
    "file_catalog = \"catalog.csv\"\n",
    "file_tar = \"compressed.tar\"\n",
    "\n",
    "# Se descargan solo si no existen\n",
    "if not os.path.exists(file_catalog):\n",
    "    print(\"Descargando catalog.csv...\")\n",
    "    urllib.request.urlretrieve(url_catalog, file_catalog)\n",
    "\n",
    "if not os.path.exists(file_tar):\n",
    "    print(\"Descargando compressed.tar...\")\n",
    "    urllib.request.urlretrieve(url_tar, file_tar)\n",
    "\n",
    "print(\"Descarga de archivos completa.\")\n",
    "\n",
    "# Descompresion del catalogo\n",
    "# Se descomprimen los archivos\n",
    "if not os.path.exists(\"compressed\"):\n",
    "    with tarfile.open(file_tar, \"r\") as tar:\n",
    "        tar.extractall(\"compressed\")\n",
    "        print(\"Archivos extraídos en la carpeta 'compressed'\\n\")\n",
    "else:\n",
    "    print(\"La carpeta 'compressed' ya existe, no se vuelve a extraer.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08f79b",
   "metadata": {},
   "source": [
    "#### Cargar el catálogo y explorar el contenido de sus columnas.  ¿Qué representa cada una?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "ea9eac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del catálogo:\n",
      "Index(['EPL Id', 'Título', 'Autor', 'Géneros', 'Colección', 'Volumen',\n",
      "       'Año publicación', 'Sinopsis', 'Páginas', 'Revisión', 'Idioma',\n",
      "       'Publicado', 'Estado', 'Valoración', 'Nº Votos', 'Enlace(s)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Se carga el catalogo\n",
    "df_catalog = pd.read_csv(\"catalog.csv\")\n",
    "\n",
    "# Se muestran las columnas del catalogo\n",
    "print(\"Columnas del catálogo:\")\n",
    "print(df_catalog.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37dc58",
   "metadata": {},
   "source": [
    "#### Significado de las columnas\n",
    "\n",
    "EPL Id: Id del libro en el catálogo.\n",
    "\n",
    "Título: Título del libro.\n",
    "\n",
    "Autor: Autor del libro.\n",
    "\n",
    "Géneros: Géneros del libro (una lista de géneros para cada libro).\n",
    "\n",
    "Colección: Colección, serie o saga a la que pertenece el libro.\n",
    "\n",
    "Volumen: Número del volumen del libro dentro de la colección.\n",
    "\n",
    "Año publicación: Año de publicación del libro.\n",
    "\n",
    "Sinopsis: Descripción o resumen del contenido del libro.\n",
    "\n",
    "Páginas: Cantidad de páginas.\n",
    "\n",
    "Revisión: Información editorial o revisión del texto.\n",
    "\n",
    "Idioma: Idioma del libro.\n",
    "\n",
    "Publicado: Estado o fecha de publicación.\n",
    "\n",
    "Estado: Estado del libro dentro del catálogo.\n",
    "\n",
    "Valoración: Valoración promedio de los usuarios.\n",
    "\n",
    "Nº Votos: Cantidad de votos recibidos por los usuarios.\n",
    "\n",
    "Enlace(s): Enlaces relacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a48b67",
   "metadata": {},
   "source": [
    "#### Filtrar las entradas del catálogo, de manera de quedarse solamente con los libros en idioma español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "6dc835b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalog = df_catalog[df_catalog['Idioma'] == 'Español']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afe504",
   "metadata": {},
   "source": [
    "#### Limitar las entradas del catálogo a las que tenga su correspondiente libro digital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "9b7ebbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos EPUB disponibles: 8958\n"
     ]
    }
   ],
   "source": [
    "path_books = 'compressed/compressed'\n",
    "\n",
    "# Se crea una lista con los epubs en path_books\n",
    "epubs = [f for f in os.listdir(path_books) if f.endswith(\".epub\")]\n",
    "\n",
    "print(f\"Total de archivos EPUB disponibles: {len(epubs)}\")\n",
    "\n",
    "# Se crea un conjunto de ids válidos, es decir, se acumulan los ids de los epubs que existen en la ruta path_books\n",
    "valids_id = set()\n",
    "for f in epubs:\n",
    "    try:\n",
    "        valids_id.add(int(f.replace(\".epub\", \"\")))\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "# Se reduce el catálogo a aquellos libros que tienen su versión digital \n",
    "df_catalog = df_catalog[df_catalog['EPL Id'].isin(valids_id)].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5468d4",
   "metadata": {},
   "source": [
    "# Definición de las clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8ad0a",
   "metadata": {},
   "source": [
    "#### Analizar la distribución de libros por categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "8e2db753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama         0.134070\n",
       "Otros         0.118218\n",
       "Aventuras     0.111632\n",
       "Policial      0.111409\n",
       "Realista      0.095334\n",
       "Intriga       0.076914\n",
       "Histórico     0.065975\n",
       "Filosofía     0.061733\n",
       "Historia      0.059500\n",
       "Fantástico    0.052467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se separan los géneros y se cuentan individualmente\n",
    "all_genres = df_catalog['Géneros'].dropna().str.split(r',\\s*')\n",
    "\n",
    "# Se cuentan los géneros, utilizando una doble compresión.\n",
    "# se toma cada sublista (es decir, cada lista de géneros para cada libro) en all_genres y a cada una de ellas, se les toma cada uno de los géneros\n",
    "# y se aplanan en una lista, donde Counter cuenta la cantidad de ocurrencias de cada uno de los géneros en la lista total \n",
    "genre_counter = Counter([g for sublist in all_genres for g in sublist])\n",
    "\n",
    "# Se crea un Series de pandas y se ordenan las ocurrencias de cada género, de manera descendente\n",
    "genre_proportion = pd.Series(genre_counter).sort_values(ascending=False)  / len(all_genres)\n",
    "\n",
    "genre_proportion.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e53b67",
   "metadata": {},
   "source": [
    "#### Eliminar el género Otros por ser una categoría redundante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "483d2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan los libros con únicamente el género \"Otros\"\n",
    "df_catalog = df_catalog[~df_catalog['Géneros'].str.fullmatch(r'Otros', na=False)]\n",
    "\n",
    "# Se elimina el género \"Otros\" de los demás libros\n",
    "df_catalog['Géneros'] = (\n",
    "    df_catalog['Géneros']\n",
    "    .str.replace(r',?\\s*Otros', '', regex=True)\n",
    "    .str.strip(', ')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fa072",
   "metadata": {},
   "source": [
    "#### Proponer y justificar un criterio para elegir un único género cuando un libro tenga varios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "76efc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define una función para seleccionar el género con menor aparición global para cada libro\n",
    "def pick_rarest_genre(genres):\n",
    "    if pd.isna(genres):\n",
    "        return None\n",
    "    genre_list = [g.strip() for g in genres.split(',')]\n",
    "    # Ordenar por frecuencia (de menor a mayor)\n",
    "    rarest = min(genre_list, key=lambda g: genre_counter.get(g, 0))\n",
    "    return rarest\n",
    "\n",
    "# Se crea una columna con el género seleccionado para cada libro\n",
    "df_catalog['Género_único'] = df_catalog['Géneros'].apply(pick_rarest_genre)\n",
    "\n",
    "# Se elimina la columna \"Géneros\" del catálogo\n",
    "df_catalog.drop(columns=['Géneros'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b32c57",
   "metadata": {},
   "source": [
    "#### Reportar la distribución final de libros por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "b544e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Género_único\n",
       "Realista           0.085018\n",
       "Drama              0.081098\n",
       "Policial           0.076320\n",
       "Aventuras          0.074237\n",
       "Intriga            0.073012\n",
       "Histórico          0.058434\n",
       "Historia           0.047287\n",
       "Filosofía          0.044469\n",
       "Fantástico         0.034669\n",
       "Ciencia ficción    0.034179\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se cuenta la cantidad de apariciones de cada género en la columna de 'Genero_unico'\n",
    "final_distribution = df_catalog['Género_único'].value_counts()\n",
    "\n",
    "final_distribution = final_distribution / df_catalog.shape[0]\n",
    "\n",
    "final_distribution.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83505b75",
   "metadata": {},
   "source": [
    "#### Separar los libros para definir conjuntos de entrenamiento y testeo utilizando las proporciones 75/25. Fijar la semilla para reproducibilidad utilizando su número de padrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "ca20128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del catálogo completo: (8163, 17)\n",
      "Tamaño del conjunto de entrenamiento: (6122, 15)\n",
      "Tamaño del conjunto de testeo: (2041, 15)\n"
     ]
    }
   ],
   "source": [
    "# Se extraen los géneros únicos\n",
    "unique_genre = df_catalog['Género_único'].unique()\n",
    "\n",
    "# Se genera un diccionario con una etiqueta para cada genero (1 : unique_genre +1)\n",
    "dict_genre = {genero: idx + 1 for idx, genero in enumerate(unique_genre)}\n",
    "\n",
    "# Se cargan las etiquetas para cada género en el df\n",
    "df_catalog['Etiqueta_género'] = df_catalog['Género_único'].map(dict_genre)\n",
    "\n",
    "# Los datos de entrada, son seleccionados sin incluir las etiquetas ni su género\n",
    "X = df_catalog.drop(columns=['Etiqueta_género', 'Género_único']) \n",
    "\n",
    "# Datos a predecir\n",
    "y = df_catalog[\"Etiqueta_género\"]\n",
    "\n",
    "# Número de padrón\n",
    "student_id = 104241\n",
    "\n",
    "# Se separan en datos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=student_id,\n",
    ")\n",
    "\n",
    "print('Tamaño del catálogo completo:', df_catalog.shape)\n",
    "print('Tamaño del conjunto de entrenamiento:', X_train.shape)\n",
    "print('Tamaño del conjunto de testeo:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24050d",
   "metadata": {},
   "source": [
    "# Preprocesamiento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426b651",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "00bc6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_books = 'compressed/compressed'\n",
    "\n",
    "def get_text_epub(epub_path):\n",
    "\n",
    "    try:\n",
    "        # Se abre el archivo epub\n",
    "        book = epub.read_epub(epub_path)\n",
    "        \n",
    "        chapters_list = []\n",
    "\n",
    "        # Se recorren todos los documentos XHTML del libro\n",
    "        for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
    "            \n",
    "            # Se obtiene el contenido del documento XHTML\n",
    "            xhtml_content = item.get_content()\n",
    "            \n",
    "            # Se usa BeautifulSoup para limpiar el xhtml y solo obtener el texto\n",
    "            soup = BeautifulSoup(xhtml_content, 'html.parser')\n",
    "            \n",
    "            # Se limpia el texto extraído\n",
    "            clean_text = soup.get_text()\n",
    "            \n",
    "            chapters_list.append(clean_text)\n",
    "        \n",
    "        # Se unifican los capitulos en un string\n",
    "        return \" \".join(chapters_list)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No se encontró el archivo: {epub_path}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando (corrupto): {epub_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def get_text_epub_id (id_book):\n",
    "    \n",
    "    # Se construye la ruta completa al libro epub\n",
    "    filename = f\"{id_book}.epub\"\n",
    "    \n",
    "    epub_path = os.path.join(path_books, filename)\n",
    "\n",
    "    return get_text_epub(epub_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cd575",
   "metadata": {},
   "source": [
    "#### El formato de libros epub es un archivo comprimido zip que contiene la metadata y estructura del libro, archivos multimedia y archivos xhtml con el texto del libro. Extraer el texto de esos archivos. Podrá realizarlo manualmente o valerse de bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "99c820d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libros en X_train: 100\n",
      "Libros en X_test: 100\n",
      "Error procesando (corrupto): compressed/compressed\\58986.epub: \"There is no item named 'OEBPS/Text/autor.xhtml' in the archive\"\n",
      "Error procesando (corrupto): compressed/compressed\\40832.epub: \"There is no item named 'META-INF/container.xml' in the archive\"\n",
      "Se completó la extracción de los textos\n",
      "Datos válidos para X_train: (98, 16)\n",
      "Datos válidos para X_test: (100, 16)\n",
      "Datos válidos para y_train: (98,)\n",
      "Datos válidos para y_test: (100,)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "\n",
    "# Se toman unas pocas muestras para evitar ejecutar con todos los archivos juntos. Se toman por índices para conservar alineados los datos.\n",
    "X_train = X_train.iloc[:n_samples].copy()\n",
    "y_train = y_train.iloc[:n_samples].copy()\n",
    "X_test = X_test.iloc[:n_samples].copy()\n",
    "y_test = y_test.iloc[:n_samples].copy()\n",
    "\n",
    "print(f\"Libros en X_train: {len(X_train)}\")\n",
    "print(f\"Libros en X_test: {len(X_test)}\")\n",
    "\n",
    "\n",
    "# Se cargan en X_train y X_test los textos de cada uno de los libros, utilizando su ID\n",
    "X_train.loc[:, 'texto'] = X_train['EPL Id'].apply(get_text_epub_id)\n",
    "X_test.loc[:, 'texto'] = X_test['EPL Id'].apply(get_text_epub_id)\n",
    "\n",
    "print(\"Se completó la extracción de los textos\")\n",
    "\n",
    "# Se eliminan las filas que no tienen texto (vacías o con NaN)\n",
    "X_train_clean = X_train.dropna(subset=['texto'])\n",
    "X_test_clean = X_test.dropna(subset=['texto'])\n",
    "\n",
    "# Se seleccionan las etiquetas que corresponden a libros cuyo texto no está vacío\n",
    "y_train_clean = y_train.loc[X_train_clean.index]\n",
    "y_test_clean = y_test.loc[X_test_clean.index]\n",
    "\n",
    "print('Datos válidos para X_train:', X_train_clean.shape)\n",
    "print('Datos válidos para X_test:', X_test_clean.shape)\n",
    "\n",
    "print('Datos válidos para y_train:', y_train_clean.shape)\n",
    "print('Datos válidos para y_test:', y_test_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdb1d0",
   "metadata": {},
   "source": [
    "#### Aplicar CountVectorizer (sklearn) al texto. Ajustar max_df, min_df y stop_words a criterio personal, justificando las decisiones. El corpus de texto completo es demasiado extenso para la memoria. Se sugiere el uso de Generators para procesar el texto plano on-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "eb7ee14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\solek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Se declara el generator, para procesar el texto por partes\n",
    "def text_generator(df_clean):\n",
    "    for texto in df_clean['texto']:\n",
    "        yield texto\n",
    "\n",
    "# Se descargan las stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Se definen las stopwords en español\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "# Se crea el vectorizador utilizando las stopwords en español (Palabras que se ignoran del texto completo).\n",
    "# Se cuentan las apariciones de las palabras en los textos, \n",
    "# siendo guardados en una matriz de shape: (n_libros, n_palabras_del_vocabulario) cada posición, almacena esa cantidad de apariciones\n",
    "# Se seleccionan los porcentajes para min_df y max_df ya que se considera que palabras demasiado\n",
    "# poco frecuentes o demasiado frecuentes en el total de los libros, no aportan información significativa para distinguir entre\n",
    "# un género y otro.\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=spanish_stopwords,\n",
    "    max_df=0.9,    # Se descartan las palabras más frecuentes, las que aparecen en más del 90% de los libros\n",
    "    min_df= 0.01   # Se descartan las palabras que aparecen en menos del 1% de los libros\n",
    ")\n",
    "\n",
    "\n",
    "# Se entrena el vectorizador con todos los textos de los libros\n",
    "train_gen = list(text_generator(X_train_clean))\n",
    "X_train_vec = vectorizer.fit_transform(train_gen)\n",
    "\n",
    "test_gen = list(text_generator(X_test_clean))\n",
    "X_test_vec = vectorizer.transform(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f78656",
   "metadata": {},
   "source": [
    "#### Se desea comprobar el funcionamiento del vectorizador. Para ello, aplicar el vectorizador ya entrenado a dos obras clásicas del catálogo de diferentes géneros (por ejemplo, “Estudio en escarlata” y “Orgullo y prejuicio”). Descartar las palabras presentes en ambos libros. Luego, para cada libro, reportar las 40 palabras más frecuentes. Interpretar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "026a7f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más frecuentes en 'Alicia en el país de las maravillas' (excluyendo las que se comparten):\n",
      "alicia -> 433\n",
      "tortuga -> 64\n",
      "grifo -> 55\n",
      "conejo -> 53\n",
      "lirón -> 39\n",
      "gustaría -> 20\n",
      "bebé -> 14\n",
      "cocinera -> 13\n",
      "corten -> 13\n",
      "dodo -> 11\n",
      "mantequilla -> 11\n",
      "moraleja -> 10\n",
      "enseguida -> 10\n",
      "croquet -> 10\n",
      "jardineros -> 10\n",
      "cheshire -> 9\n",
      "pizarras -> 8\n",
      "melaza -> 8\n",
      "pescadilla -> 8\n",
      "sonrisa -> 8\n",
      "cogió -> 8\n",
      "pizca -> 7\n",
      "nadar -> 7\n",
      "lagartija -> 7\n",
      "temblorosa -> 7\n",
      "ansiedad -> 7\n",
      "centímetros -> 7\n",
      "carroll -> 6\n",
      "cerdito -> 6\n",
      "señorita -> 6\n",
      "chilló -> 6\n",
      "enfadado -> 6\n",
      "barbilla -> 6\n",
      "debería -> 6\n",
      "medía -> 5\n",
      "ujieres -> 5\n",
      "gata -> 5\n",
      "cambiado -> 5\n",
      "dedal -> 5\n",
      "gruñido -> 5\n",
      "\n",
      "Palabras más frecuentes en 'Historia de los heterodoxos españoles' (excluyendo las que se comparten):\n",
      "et -> 2822\n",
      "san -> 1633\n",
      "españa -> 1510\n",
      "juan -> 1226\n",
      "iglesia -> 1197\n",
      "siglo -> 1033\n",
      "non -> 846\n",
      "fe -> 801\n",
      "fr -> 786\n",
      "doctrina -> 740\n",
      "obispo -> 720\n",
      "espíritu -> 689\n",
      "santo -> 685\n",
      "pedro -> 679\n",
      "etc -> 645\n",
      "ad -> 625\n",
      "madrid -> 620\n",
      "inquisición -> 527\n",
      "filosofía -> 521\n",
      "cf -> 519\n",
      "españoles -> 503\n",
      "valdés -> 503\n",
      "qui -> 502\n",
      "quod -> 485\n",
      "cristo -> 474\n",
      "erasmo -> 473\n",
      "ut -> 465\n",
      "religión -> 460\n",
      "páginas -> 453\n",
      "ii -> 436\n",
      "biblioteca -> 432\n",
      "obispos -> 432\n",
      "ciencia -> 426\n",
      "francisco -> 424\n",
      "concilio -> 416\n",
      "sevilla -> 409\n",
      "per -> 408\n",
      "ley -> 397\n",
      "antonio -> 396\n",
      "carlos -> 395\n",
      "Entre los tops de palabras más frecuentes, se comparten: set()\n"
     ]
    }
   ],
   "source": [
    "# Se extraen los textos de 2 libros diferentes\n",
    "text_alice = X_train_clean.loc[X_train_clean['Título'] == 'Alicia en el país de las maravillas (il. de Marta Gómez-Pintado)', 'texto'].iloc[0]\n",
    "text_spain   = X_train_clean.loc[X_train_clean['Título'] == 'Historia de los heterodoxos españoles', 'texto'].iloc[0]\n",
    "\n",
    "\n",
    "# Se vectorizan los textos de cada libro (shapes: 1xn_vocabulario)\n",
    "X_alice = vectorizer.transform([text_alice])\n",
    "X_spain   = vectorizer.transform([text_spain])\n",
    "\n",
    "\n",
    "freq_alice = np.squeeze(np.asarray(X_alice.toarray()))\n",
    "freq_spain   = np.squeeze(np.asarray(X_spain.toarray()))\n",
    "\n",
    "# Se obtienen los índices donde realmente hay palabras\n",
    "idx_alice = set(np.where(freq_alice > 0)[0])\n",
    "idx_spain   = set(np.where(freq_spain > 0)[0])\n",
    "\n",
    "# Se obtienen las palabras en común\n",
    "common_words = idx_alice.intersection(idx_spain)\n",
    "\n",
    "# Se crean listas de las palabras únicas en cada libro\n",
    "words_alice_only = list(idx_alice - common_words)\n",
    "words_spain_only   = list(idx_spain - common_words)\n",
    "\n",
    "# Se obtiene el vocabulario en el vectorizador\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Se obtiene la cantidad de apariciones de cada palabra en cada libro\n",
    "freq_alice_filtered = [(vocabulary[i], freq_alice[i]) for i in words_alice_only]\n",
    "top_alice = sorted(freq_alice_filtered, key=lambda x: x[1], reverse=True)[:40]\n",
    "\n",
    "freq_spain_filtered = [(vocabulary[i], freq_spain[i]) for i in words_spain_only]\n",
    "top_spain = sorted(freq_spain_filtered, key=lambda x: x[1], reverse=True)[:40]\n",
    "\n",
    "\n",
    "print(\"Palabras más frecuentes en 'Alicia en el país de las maravillas' (excluyendo las que se comparten):\")\n",
    "for word, freq in top_alice:\n",
    "        print(word, '->', freq)\n",
    "\n",
    "print(\"\\nPalabras más frecuentes en 'Historia de los heterodoxos españoles' (excluyendo las que se comparten):\")\n",
    "for word, freq in top_spain:\n",
    "        print(word, '->', freq)\n",
    "\n",
    "\n",
    "shared = set(top_alice).intersection(top_spain)\n",
    "print('Entre los tops de palabras más frecuentes, se comparten:', shared)\n",
    "\n",
    "# print(X_alice.shape)\n",
    "# print(X_spain.shape)\n",
    "# print(vocabulary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bcb862",
   "metadata": {},
   "source": [
    "Dado que se eligieron 2 libros de temáticas muy diferentes, es esperable que ninguno de los libros compartan palabras en su top de 40 palabras más usadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e81e7",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7a5af",
   "metadata": {},
   "source": [
    "#### Sobre Naive Bayes (como clasificador): \n",
    "\n",
    "Es un clasificador probabilístico, que busca estimar la probabilidad de que un dato $x$ pertenezca a una clase $y$ y clasifica según qué clase tiene mayor probabilidad.\n",
    "\n",
    "En este caso, los datos son el texto de los libros, mientras que las clases, son los géneros de cada libro. Entonces, se busca que, dado un texto de un libro, se pueda predecir a qué género pertenece.\n",
    "\n",
    "#### Sobre la hipótesis Naive:\n",
    "\n",
    "La hipótesis Naive se basa en asumir que todas las palabras son independientes entre sí, dado que ya conocemos la clase de cada una.\n",
    "Si, por ejemplo, tenemos el libro \"Alicia en el país de las maravillas\", la aparición de \"conejo\" y \"alicia\" es independiente entre sí dado el género.\n",
    "Lo cual, no es estrictamente cierto.\n",
    "\n",
    "#### Sobre Naive Bayes Multinomial:\n",
    "\n",
    "En este modelo, la probabilidad asignada a cada clase (género del libro), dado que se tiene la muestra x (el texto del libro en este caso), es:\n",
    "\n",
    "$$\n",
    "p(y \\mid x) \\propto p(y) \\prod_{i=1}^{n} p(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "Esto nace del teorema de Bayes:\n",
    "\n",
    "$$\n",
    "P(y \\mid x) = \\frac{P(x \\mid y) \\, P(y)}{P(x)}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "$y$ es la clase, en este caso el género del libro.\n",
    "\n",
    "x es el texto de un libro.\n",
    "\n",
    "$P(y \\mid x)$ Es la probabilidad de que el libro sea de la clase $y$ dado el texto del libro (lo que se busca predecir).\n",
    "\n",
    "$P(y)$ Es la probabilidad a priori de la clase $y$ (en este caso, la proporción de libros de cada género).\n",
    "\n",
    "$P(x)$ Es la probabilidad marginal de observar esas palabras.\n",
    "\n",
    "$P(x \\mid y)$ Es la probabilidad de observar las palabras x, dado que el libro es del género $y$.\n",
    "\n",
    "La hipótesis Naive, entra a la hora de calcular $P(x \\mid y)$, ya que, dado que las palabras $x_i$ se consideran independientes dado el género al que pertenece el texto del libro, entonces:\n",
    "\n",
    "$$\n",
    "P(x \\mid y) = \\prod_{i=1}^{n} P(x_i \\mid y)\n",
    "$$\n",
    "\n",
    "\n",
    "Para el caso de la multinomial, esta probabilidad (sin considerar la marginal de x) puede escribirse como:\n",
    "\n",
    "$p( y = k | x ) \\propto c_y \\cdot \\prod_{j=1}^{V}(\\theta_{j}^{(k)})^{N_j}$ \n",
    "\n",
    "Donde:\n",
    "\n",
    "$y$ es la clase, en este caso el género del libro.\n",
    "\n",
    "x es el texto de un libro, que contiene d palabras: x=($x_1$, $x_2$, ... , $x_d$).\n",
    "\n",
    "$c_y$ es la probabilidad a priori de cada clase (es decir, la cantidad de líbros de un género con respecto al total de libros).\n",
    "\n",
    "$\\theta_j$ son las probabilidades de que se encuentre en el texto la palabra $j$ ($j$ va desde 1 hasta $V$, es decir, abarca todo el vocabulario), dado el género del libro es $y$\n",
    "\n",
    "$N_j$ es la cantidad de veces que aparece la palabra j en el libro.\n",
    "\n",
    "\n",
    "Luego, dado que las probabilidades pueden volverse muy pequeñas y causar inestabilidad numérica, se trabaja con el logaritmo de la probabilidad:\n",
    "\n",
    "$log (p( y = k | x )) = cte + log(c_y) +\\sum_{j=1}^{V}(N_j \\cdot log(\\theta_{j}^{k})) $\n",
    "\n",
    "\n",
    "\n",
    "Entrenamiento del modelo:\n",
    "\n",
    "Para el entrenamiento del modelo, se comienza calculando las probabilidades a priori de cada clase, es decir, la cantidad de libros cada género con respecto al total de libros:\n",
    "\n",
    "$$\n",
    "c_k = p(y=k) = \\frac{\\#\\{y_i=k\\}}{n}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "$k$ es la clase o género\n",
    "\n",
    "$i$ es el i-ésimo libro \n",
    "\n",
    "$y_i$ es el género del i-ésimo libro\n",
    "\n",
    "$n$ es el total de libros\n",
    "\n",
    "luego, se calcula el logaritmo de esta probabilidad, para preparar el cálculo de predict_proba\n",
    "\n",
    "el paso siguiente, consiste en calcular $\\theta$ :\n",
    "\n",
    "$$\n",
    "\\theta^{k}_{j}\n",
    "=\n",
    "\\frac{N_{kj} + \\alpha_{j}}\n",
    "{\\sum_{m=1}^{V} (N_{km} + \\alpha_{m})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a46ea",
   "metadata": {},
   "source": [
    "#### Utilizando solamente numpy y scipy, implementar el clasificador MNB. El mismo debe contener los métodos fit, predict y predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "1a5565e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNB:\n",
    "\n",
    "    def __init__(self, alpha):\n",
    "        self.classes = None\n",
    "        self.class_count = None\n",
    "        self.class_log_prior = None\n",
    "        self.words_per_genre = None\n",
    "        self.log_theta = None\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # Entrenamiento\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Se convierte la entrada en un array de numpy\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # Se guardan las clases utilizando los identificadores de los géneros\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        # Se guarda la cantidad de clases existentes (cantidad de géneros)\n",
    "        K = len(self.classes)\n",
    "\n",
    "        # Se carga N como al cantidad de libros que están vectorizados y V como la cantidad de palabras del vocabulario\n",
    "        N = X.shape[0]\n",
    "        V = X.shape[1]\n",
    "\n",
    "        # Se calculan cuantos libros pertenecen a cada género\n",
    "        self.class_count = np.array([(y == c).sum() for c in self.classes], dtype=float)\n",
    "\n",
    "        # Se calcula el logaritmo de la probabilidad a priori: log (# libros por género / # libros totales) (para evitar inestabilidad numérica)\n",
    "        self.class_log_prior = np.log(self.class_count / N)\n",
    "\n",
    "        # Se crea un vector de ceros de K x V, para contar cuantas veces aparece cada palabra dentro de cada clase\n",
    "        # Es decir, se cuenta cuantas veces aparece una palabra en un libro de un determinado género\n",
    "        self.words_per_genre = np.zeros((K, V), dtype=float)\n",
    "\n",
    "        # Se realiza la cuenta de las palabras presentes en cada género para todos los géneros    \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            self.words_per_genre[idx] = X[y == c].sum(axis=0)\n",
    "\n",
    "        # Se genera el vector de alphas: si es un escalar se llena el array de V alphas con el valor dado\n",
    "        # en caso de que sea una lista (o similares), se lo convierte a array\n",
    "        if np.isscalar(self.alpha):\n",
    "            alpha_vec = np.full(V, self.alpha)\n",
    "        else:\n",
    "            alpha_vec = np.asarray(self.alpha)\n",
    "\n",
    "        # Se calcula:  N_kj + alpha_j\n",
    "        numerator = self.words_per_genre + alpha_vec  # shape (K, V)\n",
    "\n",
    "        # Se calcula: sum(N_km + alpha_m) (m va entre 1 y V)\n",
    "        denominator = numerator.sum(axis=1, keepdims=True)  # (K, 1)\n",
    "\n",
    "        # Se calculan los thetas (probabilidades de que aparezcan  cada una de las palabras del vocabulario dada cada una de las clases)\n",
    "        theta_hat = numerator / denominator\n",
    "\n",
    "        # Se calculan las log-probabilidades para los thetas\n",
    "        self.log_theta = np.log(theta_hat)\n",
    "\n",
    "\n",
    "        print('log_theta', self.log_theta.shape)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Predicción soft\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        # Dado que cada posición de la vectorización del textos es: X[i, m] = N_m\n",
    "        # Entonces, se usa el producto matricial @ para el cálculo\n",
    "        # Además, se suma el logaritmo de la probabilidad a priori\n",
    "        # todo esto para calcular el logaritmo de la probabilidad de un libro pertenezca a un determinado género, dado el texto del mismo\n",
    "        log_prob = X @ self.log_theta.T + self.class_log_prior\n",
    "\n",
    "        # Se normaliza log_prob, evitando inestabilidad numérica\n",
    "        log_norm = logsumexp(log_prob, axis=1, keepdims=True)\n",
    "\n",
    "        # Se vuelve al espacio de probabilidades finalmente\n",
    "        return np.exp(log_prob - log_norm)\n",
    "\n",
    "    # Predicción hard\n",
    "    def predict(self, X):\n",
    "        return self.classes[np.argmax(self.predict_proba(X), axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dacce3",
   "metadata": {},
   "source": [
    " #### Reportar el Accuracy y el Macro F1, tanto para entrenamiento como testeo. ¿Cuál sería la probabilidad de error asociada a un clasificador dummy en esta tarea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "9c87c211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_theta (30, 196426)\n",
      "Métricas\n",
      "Accuracy (train): 100.0%\n",
      "Accuracy (test): 28.0%\n",
      "Macro F1 (train): 100.0%\n",
      "Macro F1 (test): 13.407%\n"
     ]
    }
   ],
   "source": [
    "model = MNB(alpha = 0.1)\n",
    "\n",
    "model.fit(X_train_vec,y_train_clean)\n",
    "\n",
    "# Se obtienen las predicciones del modelo\n",
    "y_pred_train = model.predict(X_train_vec)\n",
    "y_pred_test  = model.predict(X_test_vec)\n",
    "\n",
    "# Se obtienen los accuracy\n",
    "acc_train = accuracy_score(y_train_clean, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_clean, y_pred_test)\n",
    "\n",
    "# Se obtienen los Macro F1\n",
    "f1_train = f1_score(y_train_clean, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_clean, y_pred_test, average='macro')\n",
    "\n",
    "print(\"Métricas\")\n",
    "print(f'Accuracy (train): {round(acc_train *100,3)}%' )\n",
    "print(f'Accuracy (test): {round(acc_test *100,3)}%')\n",
    "print(f'Macro F1 (train): {round(f1_train*100,3)}%')\n",
    "print(f'Macro F1 (test): {round(f1_test*100,3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21554aa",
   "metadata": {},
   "source": [
    "#### Se desea efectuar un análisis cualitativo de los errores de clasificación. Para ello, seleccione las 10 obras más populares (de testeo) que hayan sido clasificadas incorrectamente. Interpretar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "2617de7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPL Id</th>\n",
       "      <th>Título</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Colección</th>\n",
       "      <th>Volumen</th>\n",
       "      <th>Año publicación</th>\n",
       "      <th>Sinopsis</th>\n",
       "      <th>Páginas</th>\n",
       "      <th>Revisión</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Publicado</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Valoración</th>\n",
       "      <th>Nº Votos</th>\n",
       "      <th>Enlace(s)</th>\n",
       "      <th>texto</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred_test</th>\n",
       "      <th>es_correcta</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>4765</td>\n",
       "      <td>Don Quijote de la Mancha (IV CENTENARIO)</td>\n",
       "      <td>Miguel de Cervantes Saavedra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1605</td>\n",
       "      <td>Poco puede decirse del Quijote que no se haya ...</td>\n",
       "      <td>1511</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:25-04-2025</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>9.4</td>\n",
       "      <td>256</td>\n",
       "      <td>B0FEB27EF355F81608FD011F90009ADA3F467152</td>\n",
       "      <td>\\n\\n\\n\\nEL INGENIOSO CABALLERO DON QUIJOTE DE ...</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>2406.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2619</td>\n",
       "      <td>El corazón de las tinieblas [T. Araceli e Isabel]</td>\n",
       "      <td>Joseph Conrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1899</td>\n",
       "      <td>Tejida en torno a una anécdota mínima —el viaj...</td>\n",
       "      <td>167</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:10-07-2025</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>8.3</td>\n",
       "      <td>80</td>\n",
       "      <td>94893B9F3B37AE7130A69D15925D3BA4259FF175</td>\n",
       "      <td>\\n\\n\\n\\n\\nSobre el autor\\n\\n\\n\\nJózef Teodor K...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24611</th>\n",
       "      <td>6777</td>\n",
       "      <td>Tao Te Ching</td>\n",
       "      <td>Lao-Tsé</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-500</td>\n",
       "      <td>Las enseñanzas del Tao Te Ching o «Libro del S...</td>\n",
       "      <td>92</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:27-12-2021</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64</td>\n",
       "      <td>B1A63FEC8EF77D1758F8279FD5387A216E812B30</td>\n",
       "      <td>\\n\\n\\n\\n\\r\\n    Índice de contenido\\r\\n  \\n\\nC...</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37644</th>\n",
       "      <td>7528</td>\n",
       "      <td>Don Camilo</td>\n",
       "      <td>Giovanni Guareschi</td>\n",
       "      <td>Don Camilo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>En un mundo pequeñito donde se mueven pocos ce...</td>\n",
       "      <td>248</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:15-04-2020</td>\n",
       "      <td>Disp.</td>\n",
       "      <td>8.6</td>\n",
       "      <td>58</td>\n",
       "      <td>59017CDFE20BD1C1759FB3C2A58A0830FDB6CAF8</td>\n",
       "      <td>\\n\\n\\n\\nAquí,\\r\\n  con tres historias y una re...</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>498.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57869</th>\n",
       "      <td>31698</td>\n",
       "      <td>El Hobbit (ilustrado por Jemima Catlin)</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>Legendarium</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>Bilbo Bolsón disfruta de una vida sencilla y a...</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Español</td>\n",
       "      <td>P:18-07-2016</td>\n",
       "      <td>Disp.</td>\n",
       "      <td>9.3</td>\n",
       "      <td>45</td>\n",
       "      <td>WMVUU247P6QDWM5445URL2RAN2LOVNLD</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBilbo Bolsón disfruta...</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>418.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29371</th>\n",
       "      <td>19706</td>\n",
       "      <td>El arte de la guerra (v. Thomas Cleary)</td>\n",
       "      <td>Sun Tzu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-350</td>\n",
       "      <td>La versión de Thomas Cleary de El arte de la g...</td>\n",
       "      <td>64</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:06-05-2021</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>8.8</td>\n",
       "      <td>46</td>\n",
       "      <td>5C37DA8D071D261AB20F1F298E87BE258E623B5E</td>\n",
       "      <td>\\n\\n\\n\\nÍndice de contenido\\n\\nCubierta\\n\\n\\nE...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>404.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>2892</td>\n",
       "      <td>Dersú Uzalá</td>\n",
       "      <td>Vladímir Arséniev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1923</td>\n",
       "      <td>Vladímir Arséniev rememora en este libro las a...</td>\n",
       "      <td>294</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:28-02-2024</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>8.5</td>\n",
       "      <td>44</td>\n",
       "      <td>16F7609537208F85E78FDD991704770AE0A2E504</td>\n",
       "      <td>\\n\\n\\n\\n\\r\\n    Índice de contenido\\r\\n  \\n\\nC...</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10892</th>\n",
       "      <td>4549</td>\n",
       "      <td>La señora Dalloway</td>\n",
       "      <td>Virginia Woolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>En esta novela, la escritora nos transmite una...</td>\n",
       "      <td>171</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:02-12-2023</td>\n",
       "      <td>Ver.</td>\n",
       "      <td>8.3</td>\n",
       "      <td>43</td>\n",
       "      <td>FE3E17A3594BDBC45786B70C8075F17FEC1F2455</td>\n",
       "      <td>\\n\\n\\n\\nPRÓLOGO\\n\\nVirginia Woolf nace en Lond...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>356.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68239</th>\n",
       "      <td>8416</td>\n",
       "      <td>El jardín secreto</td>\n",
       "      <td>Frances Hodgson Burnett</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1909</td>\n",
       "      <td>Mary es una niña inglesa nacida en la India. S...</td>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Español</td>\n",
       "      <td>P:21-11-2013</td>\n",
       "      <td>Disp.</td>\n",
       "      <td>8.9</td>\n",
       "      <td>36</td>\n",
       "      <td>626ABF8815DEA4796009AFF54080E88B6F8CC554</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\nMary es una niña i...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>320.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>28881</td>\n",
       "      <td>La sonata a Kreutzer</td>\n",
       "      <td>Lev Nikoláievich Tolstói</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1889</td>\n",
       "      <td>Escrita a lo largo de 1889, en una época domin...</td>\n",
       "      <td>124</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Español</td>\n",
       "      <td>A:30-06-2025</td>\n",
       "      <td>Disp.</td>\n",
       "      <td>9.1</td>\n",
       "      <td>28</td>\n",
       "      <td>QVQKX2FA7UU3ANJWRC527Q4DNDM3TNLM</td>\n",
       "      <td>\\n\\n\\n\\n\\nSobre el autor\\n\\n\\n\\nLEV NIKOLÁIEVI...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>254.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EPL Id                                             Título  \\\n",
       "1584     4765           Don Quijote de la Mancha (IV CENTENARIO)   \n",
       "84       2619  El corazón de las tinieblas [T. Araceli e Isabel]   \n",
       "24611    6777                                       Tao Te Ching   \n",
       "37644    7528                                         Don Camilo   \n",
       "57869   31698            El Hobbit (ilustrado por Jemima Catlin)   \n",
       "29371   19706            El arte de la guerra (v. Thomas Cleary)   \n",
       "9416     2892                                        Dersú Uzalá   \n",
       "10892    4549                                 La señora Dalloway   \n",
       "68239    8416                                  El jardín secreto   \n",
       "252     28881                               La sonata a Kreutzer   \n",
       "\n",
       "                              Autor    Colección  Volumen  Año publicación  \\\n",
       "1584   Miguel de Cervantes Saavedra          NaN      NaN             1605   \n",
       "84                    Joseph Conrad          NaN      NaN             1899   \n",
       "24611                       Lao-Tsé          NaN      NaN             -500   \n",
       "37644            Giovanni Guareschi   Don Camilo      1.0             1948   \n",
       "57869              J. R. R. Tolkien  Legendarium      4.0             1937   \n",
       "29371                       Sun Tzu          NaN      NaN             -350   \n",
       "9416              Vladímir Arséniev          NaN      NaN             1923   \n",
       "10892                Virginia Woolf          NaN     60.0             1925   \n",
       "68239       Frances Hodgson Burnett          NaN      NaN             1909   \n",
       "252        Lev Nikoláievich Tolstói          NaN      NaN             1889   \n",
       "\n",
       "                                                Sinopsis  Páginas  Revisión  \\\n",
       "1584   Poco puede decirse del Quijote que no se haya ...     1511       1.8   \n",
       "84     Tejida en torno a una anécdota mínima —el viaj...      167       2.1   \n",
       "24611  Las enseñanzas del Tao Te Ching o «Libro del S...       92       1.2   \n",
       "37644  En un mundo pequeñito donde se mueven pocos ce...      248       1.4   \n",
       "57869  Bilbo Bolsón disfruta de una vida sencilla y a...      245       1.0   \n",
       "29371  La versión de Thomas Cleary de El arte de la g...       64       1.4   \n",
       "9416   Vladímir Arséniev rememora en este libro las a...      294       1.2   \n",
       "10892  En esta novela, la escritora nos transmite una...      171       2.2   \n",
       "68239  Mary es una niña inglesa nacida en la India. S...      139       1.0   \n",
       "252    Escrita a lo largo de 1889, en una época domin...      124       1.1   \n",
       "\n",
       "        Idioma     Publicado Estado  Valoración  Nº Votos  \\\n",
       "1584   Español  A:25-04-2025   Ver.         9.4       256   \n",
       "84     Español  A:10-07-2025   Ver.         8.3        80   \n",
       "24611  Español  A:27-12-2021   Ver.         9.0        64   \n",
       "37644  Español  A:15-04-2020  Disp.         8.6        58   \n",
       "57869  Español  P:18-07-2016  Disp.         9.3        45   \n",
       "29371  Español  A:06-05-2021   Ver.         8.8        46   \n",
       "9416   Español  A:28-02-2024   Ver.         8.5        44   \n",
       "10892  Español  A:02-12-2023   Ver.         8.3        43   \n",
       "68239  Español  P:21-11-2013  Disp.         8.9        36   \n",
       "252    Español  A:30-06-2025  Disp.         9.1        28   \n",
       "\n",
       "                                      Enlace(s)  \\\n",
       "1584   B0FEB27EF355F81608FD011F90009ADA3F467152   \n",
       "84     94893B9F3B37AE7130A69D15925D3BA4259FF175   \n",
       "24611  B1A63FEC8EF77D1758F8279FD5387A216E812B30   \n",
       "37644  59017CDFE20BD1C1759FB3C2A58A0830FDB6CAF8   \n",
       "57869          WMVUU247P6QDWM5445URL2RAN2LOVNLD   \n",
       "29371  5C37DA8D071D261AB20F1F298E87BE258E623B5E   \n",
       "9416   16F7609537208F85E78FDD991704770AE0A2E504   \n",
       "10892  FE3E17A3594BDBC45786B70C8075F17FEC1F2455   \n",
       "68239  626ABF8815DEA4796009AFF54080E88B6F8CC554   \n",
       "252            QVQKX2FA7UU3ANJWRC527Q4DNDM3TNLM   \n",
       "\n",
       "                                                   texto  y_true  y_pred_test  \\\n",
       "1584   \\n\\n\\n\\nEL INGENIOSO CABALLERO DON QUIJOTE DE ...      19            6   \n",
       "84     \\n\\n\\n\\n\\nSobre el autor\\n\\n\\n\\nJózef Teodor K...       2            6   \n",
       "24611  \\n\\n\\n\\n\\r\\n    Índice de contenido\\r\\n  \\n\\nC...      17            9   \n",
       "37644  \\n\\n\\n\\nAquí,\\r\\n  con tres historias y una re...      25            6   \n",
       "57869  \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBilbo Bolsón disfruta...      16           19   \n",
       "29371  \\n\\n\\n\\nÍndice de contenido\\n\\nCubierta\\n\\n\\nE...       3            9   \n",
       "9416   \\n\\n\\n\\n\\r\\n    Índice de contenido\\r\\n  \\n\\nC...      30           19   \n",
       "10892  \\n\\n\\n\\nPRÓLOGO\\n\\nVirginia Woolf nace en Lond...       2            4   \n",
       "68239  \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\nMary es una niña i...      28            4   \n",
       "252    \\n\\n\\n\\n\\nSobre el autor\\n\\n\\n\\nLEV NIKOLÁIEVI...       4            2   \n",
       "\n",
       "       es_correcta   score  \n",
       "1584         False  2406.4  \n",
       "84           False   664.0  \n",
       "24611        False   576.0  \n",
       "37644        False   498.8  \n",
       "57869        False   418.5  \n",
       "29371        False   404.8  \n",
       "9416         False   374.0  \n",
       "10892        False   356.9  \n",
       "68239        False   320.4  \n",
       "252          False   254.8  "
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se genera un dataset de testeo para trabajar cómodamente\n",
    "df_test_clean = X_test_clean.copy()\n",
    "df_test_clean[\"y_true\"] = y_test_clean\n",
    "df_test_clean[\"y_pred_test\"] = y_pred_test\n",
    "\n",
    "# Se crea una columna con booleanos, para determinar si la predicción fue correcta (True = coinciden)\n",
    "df_test_clean[\"es_correcta\"] = (df_test_clean[\"y_true\"] == df_test_clean[\"y_pred_test\"])\n",
    "\n",
    "# Se seleccionan solo los errores\n",
    "errors = df_test_clean[df_test_clean[\"es_correcta\"] == False].copy()\n",
    "\n",
    "# Se crea una columna con el score, considerando la cantidad de votos y la valoración promedio\n",
    "errors[\"score\"] = errors[\"Valoración\"] * errors[\"Nº Votos\"]\n",
    "\n",
    "# Se ordena por este score de mayor a menor y tomar los del top 10\n",
    "errors_rank10 = errors.sort_values(\"score\", ascending=False).head(10)\n",
    "\n",
    "# Se muestra el top10 más valorado\n",
    "errors_rank10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
